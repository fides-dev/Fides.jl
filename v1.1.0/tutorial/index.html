<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Tutorial · Fides.jl</title><meta name="title" content="Tutorial · Fides.jl"/><meta property="og:title" content="Tutorial · Fides.jl"/><meta property="twitter:title" content="Tutorial · Fides.jl"/><meta name="description" content="Documentation for Fides.jl."/><meta property="og:description" content="Documentation for Fides.jl."/><meta property="twitter:description" content="Documentation for Fides.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/custom_theme.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">Fides.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Tutorial</a><ul class="internal"><li><a class="tocitem" href="#Input-a-Function-to-Minimize"><span>Input - a Function to Minimize</span></a></li><li><a class="tocitem" href="#Optimization-with-a-Hessian-Approximation"><span>Optimization with a Hessian Approximation</span></a></li><li><a class="tocitem" href="#Optimization-with-a-User-Provided-Hessian"><span>Optimization with a User-Provided Hessian</span></a></li><li><a class="tocitem" href="#Performance-tip:-Computing-Derivatives-and-Objective-Simultaneously"><span>Performance tip: Computing Derivatives and Objective Simultaneously</span></a></li></ul></li><li><a class="tocitem" href="../API/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Tutorial</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Tutorial</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/fides-dev/Fides.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/fides-dev/Fides.jl/blob/main/docs/src/tutorial.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Tutorial"><a class="docs-heading-anchor" href="#Tutorial">Tutorial</a><a id="Tutorial-1"></a><a class="docs-heading-anchor-permalink" href="#Tutorial" title="Permalink"></a></h1><p>This overarching tutorial describes how to solve an optimization problem with Fides. It further provides performance tips for computationally intensive objective functions.</p><h2 id="Input-a-Function-to-Minimize"><a class="docs-heading-anchor" href="#Input-a-Function-to-Minimize">Input - a Function to Minimize</a><a id="Input-a-Function-to-Minimize-1"></a><a class="docs-heading-anchor-permalink" href="#Input-a-Function-to-Minimize" title="Permalink"></a></h2><p>Fides requires a function to minimize, its gradient and optionally its Hessian. In this tutorial, we use the nonlinear Rosenbrock function:</p><p class="math-container">\[f(x_1, x_2) = (1.0 - x_1)^2 + 100.0(x_2 - x_1^2)^2\]</p><p>The objective function is expected to take a vector input  and return a scalar:</p><pre><code class="language-julia hljs">function f(x)
    return (1.0 - x[1])^2 + 100.0 * (x[2] - x[1]^2)^2
end</code></pre><p>Where <code>x</code> may be either a <code>Vector</code> or a <code>ComponentVector</code> from <a href="https://github.com/SciML/ComponentArrays.jl">ComponentArrays.jl</a>. Fides also requires a gradient function, and optionally a Hessian function. In this example, for convenience we compute both via automatic differentiation using <a href="https://github.com/JuliaDiff/ForwardDiff.jl">ForwardDiff.jl</a>:</p><pre><code class="language-julia hljs">using ForwardDiff
grad! = (g, x) -&gt; ForwardDiff.gradient!(g, f, x)
hess! = (H, x) -&gt; ForwardDiff.hessian!(H, f, x)</code></pre><p>Both the gradient and Hessian functions are expected to be in-place on the form; <code>grad!(g, x)</code> and <code>hess!(H, x)</code>.</p><h2 id="Optimization-with-a-Hessian-Approximation"><a class="docs-heading-anchor" href="#Optimization-with-a-Hessian-Approximation">Optimization with a Hessian Approximation</a><a id="Optimization-with-a-Hessian-Approximation-1"></a><a class="docs-heading-anchor-permalink" href="#Optimization-with-a-Hessian-Approximation" title="Permalink"></a></h2><p>Given an objective function and its gradient, the optimization is performed in a two-step procedure. First, a <code>FidesProblem</code> is created.</p><pre><code class="language-julia hljs">using Fides
lb = [-2.0, -2.0]
ub = [ 2.0,  2.0]
x0 = [ 2.0,  2.0]
prob = FidesProblem(f, grad!, x0; lb = lb, ub = ub)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"><span class="sgr1">FidesProblem</span> with 2 parameters to estimate</code></pre><p>Where <code>x0</code> is the initial guess for parameter estimation, and <code>lb</code> and <code>ub</code> are the lower and upper parameter bounds (defaulting to <code>-Inf</code> and <code>Inf</code> if unspecified). The problem is then minimized by calling <code>solve</code>. When the Hessian is unavailable or too expensive to compute, a Hessian approximation is provided during this step:</p><pre><code class="language-julia hljs">sol = solve(prob, Fides.BFGS())</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"><span class="sgr1">FidesSolution</span>
---------------- <span class="sgr1">Summary</span> ---------------
min(f)                = 2.16e-13
Parameters estimated  = 2
Optimiser iterations  = 22
Runtime               = 2.2e-02s
</code></pre><p>Several Hessian approximations are supported (see the <a href="../API/#API">API</a>), and <code>BFGS</code> generally performs well. Additional tuning options can be set by providing a <a href="../API/#Fides.FidesOptions"><code>FidesOptions</code></a> struct via the <code>options</code> keyword in <code>solve</code>, and a full list of available options can be found in the <a href="../API/#API">API</a> documentation.</p><h2 id="Optimization-with-a-User-Provided-Hessian"><a class="docs-heading-anchor" href="#Optimization-with-a-User-Provided-Hessian">Optimization with a User-Provided Hessian</a><a id="Optimization-with-a-User-Provided-Hessian-1"></a><a class="docs-heading-anchor-permalink" href="#Optimization-with-a-User-Provided-Hessian" title="Permalink"></a></h2><p>If the Hessian (or a suitable approximation such as the <a href="https://en.wikipedia.org/wiki/Gauss%E2%80%93Newton_algorithm">Gauss–Newton approximation</a>) is available, providing it can improve convergence. To provide a Hessian function to <code>FidesProblem</code> do:</p><pre><code class="language-julia hljs">prob = FidesProblem(f, grad!, x0; hess! = hess!, lb = lb, ub = ub)</code></pre><p>Then, when solving the problem use the <code>Fides.CustomHessian()</code> Hessian option:</p><pre><code class="language-julia hljs">sol = solve(prob, Fides.CustomHessian())</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"><span class="sgr1">FidesSolution</span>
---------------- <span class="sgr1">Summary</span> ---------------
min(f)                = 3.59e-22
Parameters estimated  = 2
Optimiser iterations  = 17
Runtime               = 1.3e-02s
</code></pre><h2 id="Performance-tip:-Computing-Derivatives-and-Objective-Simultaneously"><a class="docs-heading-anchor" href="#Performance-tip:-Computing-Derivatives-and-Objective-Simultaneously">Performance tip: Computing Derivatives and Objective Simultaneously</a><a id="Performance-tip:-Computing-Derivatives-and-Objective-Simultaneously-1"></a><a class="docs-heading-anchor-permalink" href="#Performance-tip:-Computing-Derivatives-and-Objective-Simultaneously" title="Permalink"></a></h2><p>Internally, the objective function and its derivatives are computed simultaneously by Fides. Hence, runtime can be reduced if is is possible to reuse intermediate quantities between the objective and derivative computations. To take advantage of this, a <code>FidesProblem</code> can be created with a function that computes the objective and gradient (and optionally the Hessian) for a given input. For example, when only the gradient is available:</p><pre><code class="language-julia hljs">function fides_obj(x)
    obj = f(x)
    g   = ForwardDiff.gradient(f, x)
    return (obj, g)
end

prob = FidesProblem(fides_obj, x0; lb = lb, ub = ub)
sol = solve(prob, Fides.BFGS())</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"><span class="sgr1">FidesSolution</span>
---------------- <span class="sgr1">Summary</span> ---------------
min(f)                = 2.16e-13
Parameters estimated  = 2
Optimiser iterations  = 22
Runtime               = 2.2e-02s
</code></pre><p>When a Hessian function is available, do:</p><pre><code class="language-julia hljs">function fides_obj(x)
    obj = f(x)
    g   = ForwardDiff.gradient(f, x)
    H   = ForwardDiff.hessian(f, x)
    return (obj, g, H)
end

prob = FidesProblem(fides_obj, x0; lb = lb, ub = ub)
sol = solve(prob, Fides.CustomHessian())</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"><span class="sgr1">FidesSolution</span>
---------------- <span class="sgr1">Summary</span> ---------------
min(f)                = 3.59e-22
Parameters estimated  = 2
Optimiser iterations  = 17
Runtime               = 1.3e-02s
</code></pre><p>In this simple example, no runtime benefit is obtained as no quantities are reused between objective and derivative computations. However, if quantities can be reused (for example, when gradients are computed for ODE models), runtime can be noticeably reduced.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../API/">API »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.10.1 on <span class="colophon-date" title="Saturday 19 April 2025 11:18">Saturday 19 April 2025</span>. Using Julia version 1.11.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
